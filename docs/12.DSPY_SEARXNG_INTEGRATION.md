# DSPy + SearXNG Integration Guide

Complete guide to integrate DSPy (AI reasoning framework) with SearXNG (web search) in SearchFlow.

---

## Understanding the Stack

### What Each Component Does

| Component      | Purpose                  | Role                                                |
| -------------- | ------------------------ | --------------------------------------------------- |
| **SearXNG**    | Privacy-first web search | Fetches live data from multiple search engines      |
| **DSPy**       | AI reasoning framework   | Structures, cleans, and reasons over search results |
| **FastAPI**    | Web framework            | Exposes search as HTTP endpoints                    |
| **SearchFlow** | Project wrapper          | Combines all three                                  |

### Data Flow

```
User Query
    ‚Üì
FastAPI Endpoint
    ‚Üì
SearXNG (searches web)
    ‚Üì
Raw Results (10-20 links, snippets)
    ‚Üì
DSPy Pipeline (AI reasoning)
    ‚Üì
Structured Output (JSON + Markdown)
    ‚Üì
User
```

---

## Part 1: Environment Variables Explained

These go in `.env`:

```env
# SearXNG Configuration
SEARXNG_URL=http://localhost:8888          # Where SearXNG is running
SEARXNG_SECRET=your_secret_key_here        # Security key (for production)
SEARXNG_ENGINES=google,bing,duckduckgo     # Which engines to search

# LLM Configuration (for DSPy)
OPENAI_API_KEY=sk-...                      # OpenAI API key for DSPy
LLM_MODEL=gpt-4o-mini                      # Which model DSPy uses

# FastAPI Configuration
DEBUG=false
LOG_LEVEL=INFO
ALLOWED_ORIGINS=http://localhost,http://localhost:8007
```

### Environment Variables Breakdown

#### `SEARXNG_URL`

- **What it is**: Base URL of your SearXNG instance
- **Where it's used**: DSPy retriever sends HTTP requests here
- **Example**: `http://localhost:8888` (local) or `https://search.example.com` (production)
- **Why you need it**: DSPy doesn't have built-in SearXNG support; you must tell it where to find search results

#### `SEARXNG_SECRET`

- **What it is**: Security token for authenticated access
- **Where it's used**: When SearXNG is behind authentication or rate limiting
- **Generate**:
  ```bash
  openssl rand -hex 32
  ```
- **Why you need it**: Prevents unauthorized access in production

#### `SEARXNG_ENGINES`

- **What it is**: Comma-separated list of search engines SearXNG should use
- **Options**: `google`, `bing`, `duckduckgo`, `startpage`, `brave`, `wikipedia`, etc.
- **Example**: `duckduckgo,brave,startpage` (privacy-focused engines)
- **Why you need it**: Different engines = different results; choose based on your use case

---

## Part 2: Do You Need API Access?

### ‚úÖ You DO NOT Need External APIs

SearXNG is **self-hosted**, so:

```
‚ùå Google Search API (needs API key, costs money)
‚ùå SerpAPI (needs API key, costs money)
‚úÖ SearXNG (free, self-hosted, no API key needed)
```

### What You Need Instead

1. **SearXNG running** (Docker container)
2. **DSPy installed** (Python package)
3. **An LLM API key** (for DSPy reasoning - OpenAI, Anthropic, etc.)

---

## Part 3: Installation

### Step 1: Install DSPy

```bash
pip install dspy-ai requests
```

### Step 2: Start SearXNG

Already done with `make docker-up`, but verify:

```bash
curl http://localhost:8888
```

### Step 3: Set Environment Variables

Copy `.env.example` to `.env`:

```bash
cp .env.example .env
```

Edit `.env`:

```env
SEARXNG_URL=http://localhost:8888
OPENAI_API_KEY=sk-your-key-here
LLM_MODEL=gpt-4o-mini
```

---

## Part 4: DSPy + SearXNG Implementation

### Create `app/search/dspy_retriever.py`

```python
"""
DSPy-compatible SearXNG Retriever

Bridges DSPy and SearXNG for web search in AI pipelines.
"""

import requests
import dspy
import logging
from typing import List, Optional
from app.core.config import settings

logger = logging.getLogger(__name__)


class SearXNGRetriever(dspy.Retriever):
    """DSPy retriever that uses SearXNG for web search"""

    def __init__(
        self,
        searx_url: Optional[str] = None,
        k: int = 5,
        language: str = "en"
    ):
        """
        Initialize SearXNG retriever for DSPy

        Args:
            searx_url: SearXNG base URL (defaults to settings)
            k: Number of results to retrieve
            language: Language code for search
        """
        self.searx_url = searx_url or settings.SEARXNG_URL
        self.k = k
        self.language = language

    def forward(self, query: str) -> List[dspy.Passage]:
        """
        Retrieve relevant passages from web via SearXNG

        Args:
            query: Search query string

        Returns:
            List of DSPy Passage objects with text and metadata
        """
        try:
            logger.info(f"Retrieving from SearXNG: {query}")

            response = requests.get(
                f"{self.searx_url}/search",
                params={
                    "q": query,
                    "format": "json",
                    "language": self.language,
                    "safesearch": 1,
                },
                timeout=30
            )
            response.raise_for_status()

            data = response.json()
            passages = []

            for result in data.get("results", [])[:self.k]:
                # Combine title and content for better context
                text = f"{result.get('title', '')}\n{result.get('content', '')}"

                passage = dspy.Passage(
                    text=text.strip(),
                    meta={
                        "url": result.get("url", ""),
                        "source": result.get("engine", "unknown"),
                        "title": result.get("title", "")
                    }
                )
                passages.append(passage)

            logger.info(f"Retrieved {len(passages)} passages")
            return passages

        except Exception as e:
            logger.error(f"SearXNG retrieval failed: {e}")
            return []
```

### Create `app/ai/dspy_pipeline.py`

```python
"""
DSPy Processing Pipeline

Uses DSPy for AI reasoning over search results.
"""

import dspy
import logging
import os
from typing import List, Dict, Optional
from app.search.dspy_retriever import SearXNGRetriever
from pydantic import BaseModel

logger = logging.getLogger(__name__)


# DSPy Signature: what the AI will be asked to do
class SearchQA(dspy.Signature):
    """Answer a question using web search context"""
    context = dspy.InputField(desc="Information from web search")
    question = dspy.InputField(desc="The user's question")
    answer = dspy.OutputField(desc="A comprehensive answer based on context")
    confidence = dspy.OutputField(desc="Confidence score 0-1")


class DSPyPipeline:
    """DSPy pipeline for search + reasoning"""

    def __init__(
        self,
        lm_model: Optional[str] = None,
        searx_url: Optional[str] = None,
        k_results: int = 5
    ):
        """
        Initialize DSPy pipeline

        Args:
            lm_model: LLM model to use (default: from settings)
            searx_url: SearXNG URL (default: from settings)
            k_results: Number of search results to use
        """
        # Configure LLM
        model = lm_model or os.getenv("LLM_MODEL", "gpt-4o-mini")
        api_key = os.getenv("OPENAI_API_KEY")

        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable not set")

        lm = dspy.OpenAI(
            api_key=api_key,
            model=model,
            max_tokens=1000
        )
        dspy.settings.configure(lm=lm)

        # Configure retriever
        self.retriever = SearXNGRetriever(
            searx_url=searx_url,
            k=k_results
        )

        # Create reasoning module
        self.answer = dspy.ChainOfThought(SearchQA)

    def search_and_answer(self, question: str) -> Dict:
        """
        Search the web and answer a question using DSPy

        Args:
            question: User's question

        Returns:
            Dictionary with answer, context, and confidence
        """
        try:
            logger.info(f"Processing question: {question}")

            # Step 1: Retrieve relevant passages
            passages = self.retriever(question)

            if not passages:
                return {
                    "question": question,
                    "answer": "Could not find relevant information",
                    "context": [],
                    "confidence": 0.0
                }

            # Step 2: Combine context
            context = "\n\n".join([p.text for p in passages])

            # Step 3: Use DSPy to reason and answer
            result = self.answer(
                context=context[:2000],  # Limit context size
                question=question
            )

            # Step 4: Extract confidence
            try:
                confidence = float(result.confidence.split()[0])
            except:
                confidence = 0.7

            return {
                "question": question,
                "answer": result.answer,
                "context": [
                    {
                        "text": p.text[:500],
                        "url": p.meta.get("url", ""),
                        "source": p.meta.get("source", ""),
                        "title": p.meta.get("title", "")
                    }
                    for p in passages
                ],
                "confidence": confidence,
                "sources": [p.meta.get("url") for p in passages if p.meta.get("url")]
            }

        except Exception as e:
            logger.error(f"DSPy pipeline failed: {e}")
            return {
                "question": question,
                "answer": f"Error: {str(e)}",
                "context": [],
                "confidence": 0.0
            }
```

---

## Part 5: FastAPI Integration

Update `app/api/search.py`:

````python
"""
Search API Endpoints

Integrates SearXNG + DSPy for web search with AI reasoning.
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from app.ai.dspy_pipeline import DSPyPipeline
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1", tags=["search"])


class SearchRequest(BaseModel):
    """Search request model"""
    query: str
    include_context: bool = True


class SearchResult(BaseModel):
    """Search result model"""
    question: str
    answer: str
    confidence: float
    sources: List[str]
    context: Optional[List[dict]] = None


@router.post("/search", response_model=SearchResult)
async def search(request: SearchRequest) -> SearchResult:
    """
    Search and answer using DSPy + SearXNG

    Example:
    ```bash
    curl -X POST http://localhost:8007/api/v1/search \
      -H "Content-Type: application/json" \
      -d '{"query": "what is dspy"}'
    ```
    """
    try:
        logger.info(f"Search request: {request.query}")

        # Initialize DSPy pipeline
        pipeline = DSPyPipeline(k_results=5)

        # Search and answer
        result = pipeline.search_and_answer(request.query)

        # Format response
        response = SearchResult(
            question=result["question"],
            answer=result["answer"],
            confidence=result["confidence"],
            sources=result["sources"],
            context=result["context"] if request.include_context else None
        )

        return response

    except Exception as e:
        logger.error(f"Search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/search/health")
async def search_health():
    """Health check for search functionality"""
    return {
        "status": "healthy",
        "searxng": "configured",
        "dspy": "ready"
    }
````

---

## Part 6: Testing DSPy + SearXNG

### Create `tests/test_dspy_pipeline.py`

```python
"""
DSPy Pipeline Tests
"""

import pytest
import os
from app.ai.dspy_pipeline import DSPyPipeline


@pytest.mark.asyncio
class TestDSPyPipeline:
    """Test DSPy + SearXNG integration"""

    def test_pipeline_initialization(self):
        """Test DSPy pipeline can be initialized"""
        # Skip if no OpenAI key
        if not os.getenv("OPENAI_API_KEY"):
            pytest.skip("OPENAI_API_KEY not set")

        pipeline = DSPyPipeline()
        assert pipeline is not None
        assert pipeline.retriever is not None

    def test_search_and_answer(self):
        """Test search and answer functionality"""
        if not os.getenv("OPENAI_API_KEY"):
            pytest.skip("OPENAI_API_KEY not set")

        pipeline = DSPyPipeline()
        result = pipeline.search_and_answer("What is Python?")

        assert result["question"] == "What is Python?"
        assert result["answer"] is not None
        assert result["confidence"] >= 0
        assert result["confidence"] <= 1
```

### Run Tests

```bash
# With OPENAI_API_KEY set
OPENAI_API_KEY=sk-... pytest tests/test_dspy_pipeline.py -v

# Or use make
make test
```

---

## Part 7: Configuration Summary

### `.env` Template

```env
# SearXNG
SEARXNG_URL=http://localhost:8888
SEARXNG_SECRET=your_secret_key
SEARXNG_ENGINES=google,bing,duckduckgo

# LLM (for DSPy)
OPENAI_API_KEY=sk-your-key-here
LLM_MODEL=gpt-4o-mini

# FastAPI
DEBUG=false
LOG_LEVEL=INFO
ALLOWED_ORIGINS=http://localhost,http://localhost:8007
```

### What Each Variable Does

| Variable          | Purpose              | Required?                          | Example                  |
| ----------------- | -------------------- | ---------------------------------- | ------------------------ |
| `SEARXNG_URL`     | Where to search      | ‚úÖ Yes                             | `http://localhost:8888`  |
| `SEARXNG_SECRET`  | Security key         | ‚è∏Ô∏è Optional (needed in prod)       | `random_hex_string`      |
| `SEARXNG_ENGINES` | Which search engines | ‚è∏Ô∏è Optional                        | `google,bing,duckduckgo` |
| `OPENAI_API_KEY`  | LLM API key for DSPy | ‚úÖ Yes                             | `sk-...`                 |
| `LLM_MODEL`       | Which LLM to use     | ‚è∏Ô∏è Optional (default: gpt-4o-mini) | `gpt-4o-mini`            |

---

## Part 8: Complete Workflow

### Step 1: Setup

```bash
# 1. Copy environment template
cp .env.example .env

# 2. Add your OpenAI API key
echo "OPENAI_API_KEY=sk-..." >> .env

# 3. Start services
make docker-up

# 4. Install DSPy
pip install dspy-ai requests
```

### Step 2: Test

```bash
# Test the health endpoint
curl http://localhost:8007/health

# Test the search endpoint
curl -X POST http://localhost:8007/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{"query": "what is python programming"}'
```

### Step 3: Expected Response

```json
{
  "question": "what is python programming",
  "answer": "Python is a high-level, interpreted programming language known for its simplicity and readability...",
  "confidence": 0.92,
  "sources": [
    "https://www.python.org",
    "https://en.wikipedia.org/wiki/Python_(programming_language)"
  ],
  "context": [
    {
      "text": "Python is a programming language that lets you work quickly...",
      "url": "https://www.python.org",
      "source": "google",
      "title": "Welcome to Python.org"
    }
  ]
}
```

---

## Part 9: No External APIs Needed

### What You DON'T Need

```
‚ùå Google Search API ($$$, rate limits)
‚ùå SerpAPI ($$$, rate limits)
‚ùå Tavily API ($$$, rate limits)
‚ùå Bing Search API ($$$, rate limits)
```

### What You DO Have

```
‚úÖ SearXNG (free, self-hosted)
‚úÖ DSPy (free, open-source)
‚úÖ OpenAI API (paid but optional, alternatives exist)
```

### Cost Breakdown

| Component                  | Cost                       |
| -------------------------- | -------------------------- |
| SearXNG                    | $0 (self-hosted)           |
| DSPy                       | $0 (open-source)           |
| SearchFlow                 | $0 (your code)             |
| LLM (OpenAI gpt-4o-mini)   | ~$0.15 per 1M input tokens |
| **Total for 100 searches** | ~$0.01-0.05                |

---

## Part 10: Common Issues & Solutions

### Issue 1: "OPENAI_API_KEY not set"

**Solution:**

```bash
export OPENAI_API_KEY=sk-your-key
# Or add to .env file
```

### Issue 2: SearXNG returns 403

**Solution:**

```bash
# Restart with limiter config
make docker-down
make docker-up
```

### Issue 3: DSPy hangs on first query

**Solution:**

- First query downloads model weights (~1-2 seconds delay)
- Subsequent queries are faster
- This is normal behavior

### Issue 4: "No module named dspy"

**Solution:**

```bash
pip install dspy-ai
```

---

## Summary

### You Need

1. ‚úÖ **SearXNG** (for web search) - already running
2. ‚úÖ **DSPy** (for AI reasoning) - pip install
3. ‚úÖ **OpenAI API key** (for LLM) - get from openai.com
4. ‚úÖ **Environment variables** - set in `.env`

### You DON'T Need

- ‚ùå External search APIs
- ‚ùå API keys for search services
- ‚ùå Additional dependencies

### Next Steps

1. Set `OPENAI_API_KEY` in `.env`
2. Run `pip install dspy-ai requests`
3. Start services with `make docker-up`
4. Test with the curl command above
5. Integrate into your application

**SearchFlow is now a complete AI-powered search backend!** üöÄ
